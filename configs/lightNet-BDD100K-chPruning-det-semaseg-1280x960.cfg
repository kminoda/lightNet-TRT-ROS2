[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=256
subdivisions=128
width=1280
height=960
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.000005
burn_in=100

max_batches = 262500
policy=steps
steps=25000,50000,100000
scales=.5,.5,.5
gaussian_noise=1
flip=1


#sparse=1 : 2:4 structured sparsity
#L0 1280x960 0.531GFLOPS
[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=relu

#L1 640x480 2.831GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=relu

#L2 320x240 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=1
stride=1
pad=0
activation=relu

#L3 
[route]
layers=-2

#L4 320x240 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=1
stride=1
pad=0
activation=relu

#L5 320x240 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L6 320x240 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L7 320x240 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L8 320x240 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L9 
[route]
layers=-1,-3,-5,-7

#L10 320x240 1.258GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L11 320x240 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=relu

#L12 160x120 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L13 
[route]
layers=-2

#L14 160x120 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L15 160x120 0.708GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L16 160x120 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L17 160x120 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L18 160x120 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L19 
[route]
layers=-1,-3,-5,-7

#L20 160x120 0.944GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L21 160x120 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=relu

#L22 80x60 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L23 
[route]
layers=-2

#L24 80x60 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L25 80x60 0.708GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L26 80x60 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L27 80x60 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L28 80x60 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L29 
[route]
layers=-1,-3,-5,-7

#L30 80x60 0.944GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L31 80x60 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=relu

#L32 40x30 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L33 
[route]
layers=-2

#L34 40x30 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L35 40x30 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L36 40x30 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L37 40x30 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L38 40x30 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L39 
[route]
layers=-1,-3,-5,-7

#L40 40x30 0.786GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=relu

#L41 40x30 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L42 
[route]
layers=-2

#L43 40x30 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L44 40x30 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L45 
[route]
layers=-2

#L46 40x30 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L47 
[route]
layers=-4

#L48 40x30 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L49 
[route]
layers=-1,-3,-5,-6

#L50 40x30 0.629GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L51 
[route]
layers=-10,-1

#L52 40x30 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L53 40x30 0.079GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L54 
[upsample]
stride=2

#L55 
[route]
layers=-25

#L56 80x60 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L57 
[route]
layers=-1,-3

#L58 80x60 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L59 
[route]
layers=-2

#L60 80x60 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L61 80x60 0.177GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L62 80x60 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L63 80x60 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L64 80x60 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L65 
[route]
layers=-1,-3,-5,-7

#L66 80x60 0.236GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L67 80x60 0.079GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L68 
[upsample]
stride=2

#L69 
[route]
layers=-49

#L70 160x120 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L71 
[route]
layers=-1,-3

#L72 160x120 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=1
stride=1
pad=0
activation=relu

#L73 
[route]
layers=-2

#L74 160x120 0.157GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=1
stride=1
pad=0
activation=relu

#L75 160x120 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L76 160x120 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L77 160x120 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L78 160x120 0.354GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L79 
[route]
layers=-1,-3,-5,-7

#L80 160x120 0.315GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L81 160x120 0.708GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=relu

#L82 
[route]
layers=-1,-15

#L83 80x60 0.118GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L84 
[route]
layers=-2

#L85 80x60 0.118GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=relu

#L86 80x60 0.177GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L87 80x60 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L88 80x60 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L89 80x60 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

#L90 
[route]
layers=-1,-3,-5,-7

#L91 80x60 0.236GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L92 80x60 0.708GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=relu

#L93 
[route]
layers=-1,-40

#L94 40x30 0.118GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L95 
[route]
layers=-2

#L96 40x30 0.118GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=relu

#L97 40x30 0.177GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L98 40x30 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L99 40x30 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L100 40x30 0.088GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L101 
[route]
layers=-1,-3,-5,-7

#L102 40x30 0.236GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#L103 
[route]
layers=-23

#L104 160x120 1.416GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L105 160x120 0.111GFLOPS
[convolutional]
#sparse=1
filters=45
size=1
stride=1
pad=1
activation=logistic

[yolo]
mask = 0,1,2
anchors =  7, 14,  17, 21,  11, 38,  31, 40,  21, 84,  57, 69,  87,130, 148,198, 215,337
classes=10
num=9
jitter=.3
scale_x_y = 2.0
ignore_thresh = .5
truth_thresh = 1
resize=1.5
new_coords=1
names=car,bus,person,                bike,truck,motor,               train,rider,traffic_sign,    traffic_light
colormap=0,0,255, 0,0,235, 255,0,0,  128,128,0, 0,0,225, 128,255,0,  0,0,200, 255,0,128, 0,255,0  255,0,255

#L107 
[route]
layers=-16

#L108 80x60 0.708GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

#L109 80x60 0.028GFLOPS
[convolutional]
#sparse=1
filters=45
size=1
stride=1
pad=1
activation=logistic

[yolo]
mask = 3,4,5
anchors =  7, 14,  17, 21,  11, 38,  31, 40,  21, 84,  57, 69,  87,130, 148,198, 215,337
classes=10
num=9
jitter=.3
scale_x_y = 2.0
ignore_thresh = .5
truth_thresh = 1
resize=1.5
new_coords=1
names=car,bus,person,                bike,truck,motor,               train,rider,traffic_sign,    traffic_light
colormap=0,0,255, 0,0,235, 255,0,0,  128,128,0, 0,0,225, 128,255,0,  0,0,200, 255,0,128, 0,255,0  255,0,255

#L111 
[route]
layers=-9

#L112 40x30 0.708GFLOPS
[convolutional]
sparse=1
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=relu

#L113 40x30 0.014GFLOPS
[convolutional]
#sparse=1
filters=45
size=1
stride=1
pad=1
activation=logistic

[yolo]
mask = 6,7,8
anchors =  7, 14,  17, 21,  11, 38,  31, 40,  21, 84,  57, 69,  87,130, 148,198, 215,337
classes=10
num=9
jitter=.3
scale_x_y = 2.0
ignore_thresh = .5
truth_thresh = 1
resize=1.5
new_coords=1
names=car,bus,person,                bike,truck,motor,               train,rider,traffic_sign,    traffic_light
colormap=0,0,255, 0,0,235, 255,0,0,  128,128,0, 0,0,225, 128,255,0,  0,0,200, 255,0,128, 0,255,0  255,0,255
#Total :35.030GFLOPS

[route]
layers = 102,53

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[route]
layers=-2

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu
dilation=1

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu
dilation=2

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu
dilation=3

[route]
layers = -1,-3,-5,-7

# 86
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[upsample]
stride=2
#80x60

[route]
layers = -1,91,30

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[route]
layers=-2

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu
dilation=1

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu
dilation=2

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu
dilation=3

[route]
layers = -1,-3,-5,-7

# 86
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[upsample]
stride=2
#160x120

[route]
layers = -1,80,20

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[route]
layers=-2

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
sparse=1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu
dilation=1

[route]
layers = -1,-3,-5

# 86
[convolutional]
sparse=1
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[upsample]
stride=2
#320x240

[convolutional]
sparse=1
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=relu

[convolutional]
sparse=1
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=relu

[upsample]
stride=2
#640x480

[convolutional]
size=1
stride=1
pad=1
filters=20
activation=linear

[softmax]
groups=307200
stride=307200
#BGR
num=20
classes=20
colormap=128,64,128, 244,35,232, 70,70,70, 102,102,156,		190,153,153, 153,153,153, 250,170,30, 220,220,0,	107,142,35, 152,251,152, 70,130,180, 220,20,60,		 255,0,0, 0,0,142, 0,0,70, 0,60,100,	0,80,100, 0,0,230, 119,11,32, 0,0,0
